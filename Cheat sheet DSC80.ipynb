{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc0f913",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "<br>\n",
    "axis = 1 -- sum of rows\n",
    "<br>\n",
    "axis = 0 -- sum of cloumns\n",
    "<br>\n",
    "any comparison among <b>NaN</b> values will be <b>False</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad710ce9",
   "metadata": {},
   "source": [
    "| Method Name | Despriction |\n",
    "| --- | --- |\n",
    "| count | Returns the number of non-null entries in the Series |\n",
    "| unique | Returns the unique values in the Series |\n",
    "| nunique | Returns the number of unique values in the Series |\n",
    "| value_counts | Returns a Series of counts of unique values |\n",
    "| describe | Returns a Series of descriptive stats of values |\n",
    "| values | Returns an array form of the dataframe |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694c447",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "<code>df.drop(columns = [])</code> drop columns in the list<br>\n",
    "<code>df.size</code> return the total number of entries<br>\n",
    "<code>df.shape</code> return a tuple of the dimension<br>\n",
    "<code>df[~(condition)]</code> return a DataFrame that does not satisfies the condition <br>\n",
    "<code>pd.to_numeric(df[col], downcast = datatype)</code> transform column value to number <br>\n",
    "<code>pd.dropna(subset=[col1, ..., col3])</code> drop null in specific columns<br>\n",
    "<code>pd.fillna({'col1': ..., 'col2': ...})</code> fill null wth specified values in dictionary for each columns<br>\n",
    "<code>df.assign</code> & <code>df.append</code> create a copy of the DataFrame<br>\n",
    "<code>df.idxmax()</code> largest value in a column when <code>axis=0</code> largest value in a row when <code>axis=1</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b90bca",
   "metadata": {},
   "source": [
    "### Data Organizing\n",
    "<b>data selecting</b><br>\n",
    "\n",
    "<code>df[a]</code> return a serie of the column that its name matches <code>a</code><br>\n",
    "<code>df[[a]]</code> return a dataframe of the columns specified in <code>a</code><br>\n",
    "<code>df.loc[a]</code> return a series of the row that index matches <code>a</code><br>\n",
    "<code>df.loc[[a]]</code> return a dataframe of the rows that index matches elements in <code>a</code><br>\n",
    "<code>df[[bool, ..., bool]]</code> return a dataframe, find specific rows where bool are <code>True</code><br>\n",
    "<code>df.loc[idx_list, col_list]</code> return a dataframe containing rows in <code>idx_list</code> and columns in <code>col_list</code>. If idx_list or col_list is not a list yet 1 element, return series.<br>\n",
    "<code>df.loc[bool_array, col_list]</code> return a fataframe containing the rows which <code>bool_array</code> is <code>True</code> and columns in <code>col_list</code><br>\n",
    "<code>df.loc[1, :] = [..., ..., ...]</code> assign a new serie to the row<br>\n",
    "<code>df[3:5, 'Name':'PID']</code> slice the selected rows and columns(inclusive) <br>\n",
    "\n",
    "<b>groupby</b> <br>\n",
    "<code>df.groupby(col1)[col2].agg['mean', 'median']</code>return a dataframe with the mean and median of<code>col2</code> with index <code>col1</code> <br>\n",
    "<code>df.groupby(col1).agg({'col2': mean, 'col3': median})</code>return a dataframe with the mean of<code>col2</code>and the median of<code>col3</code>with index<code>col1</code> <br>\n",
    "<code>df.groupby(col1).transform(lambda x: (x-x.mean() / x.std()))</code> x represent a serie in one group of <code>col1</code>, lambda method will nomalized the value of <code>col2</code> with each groups of <code>col1</code><br>\n",
    "<code>df.groupby(col1).filter(lambda df: df['col2'].mean() >= limit)</code> filter out the group in <code>col1</code> whose mean value of <code>col2</code> is less than the limit<br>\n",
    "<code>df.groupby(col1).first()</code> return a dataframe tha contains the first observation within each group of <code>col1</code> <br>\n",
    "\n",
    "<b>pivot table</b> <br>\n",
    "<code>df.pivot_table(index='x', columns='y', values='z', aggfunc='mean')</code> return a dataframe with index <code>x</code> and the mean value of <code>z</code> within each group of <code>y</code><br>\n",
    "<code>aggfunc</code>: count, mean, max, sum, size, ...<br>\n",
    "\n",
    "<b>concat</b><br>\n",
    "<code>pd.concat([df1,df2])</code> by default, two df will be stacked together; index of both df won't change; if one column is missing, the element will be filled with <code>NaN</code>; treat concat as outer in merge<br>\n",
    "<code>pd.concat([df1,df2], axis=1)</code> two df will be combined horizontally; columns with the same name will be kept<br>\n",
    "\n",
    "<b>merge</b><br>\n",
    "<code>df1.merge(df2, how=inner, left_on = ..., right_on = ..., suffixes=('_x','_y'))</code> rows that is contained both in <code>left_on</code> and <code>right_on</code> is kept; coorsponding columns of the kept rows are kept; suffix is added to the overlapping column names in <code>df1</code> and <code>df2</code> respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74d48a",
   "metadata": {},
   "source": [
    "### String Method\n",
    "<code>df[col].str.split().str[0]</code> split the string in <code>col</code> ang get the first element of the splitted list<br>\n",
    "<code>df[col].str.strip(char)</code> clean the begninning and end char<br>\n",
    "<code>df[col].str.zfill(num)</code> if the length of string is less than <code>num</code>, then filled with zero at the beginning<br>\n",
    "<code>df[col].str.count(pattern)</code> count the number of appearance for pattern in each row<br>\n",
    "<code>df[col].str.split().str.len()</code> split the row and get the length for each list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26851a3",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "<code>df[col].plot(kind=hist, density=True, bins=20, ec='w')</code> draw a histogram with probability density<br>\n",
    "<code>df[col].plot(kind=barh, x=..., y=...)</code> draw a horizontal bar plot<br>\n",
    "<code>pd.plotting.scatter_matrix(df[['col1', 'col2', 'col3']], figsize=(8, 8));</code> draw a scatter_matrix of df beased on the columns selected<br>\n",
    "<code>df.groupby(col1)[col2].plot(kind='kde', legend=True)</code> plot the probability density function of the unique values in <code>col1</code> in respect to the values of <code>col2</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98bdba",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "<br>\n",
    "Can apply function to numpy array without for loop<br>\n",
    "pd.to_numpy() return a view of the original object, numpy array of array (not a copy of the df)<br>\n",
    "type coercion - array created with string and int contains only strings.\n",
    "<code>\n",
    "np.array['a', 1] = array(['a', '1'], dtype=str)\n",
    "np.array(['a', 1], dtype=object) = array(['a', 1], dtype=object)\n",
    "pd.Series(['a', 1]).values = array(['a', 1], dtype=object)\n",
    "pd.Series([1, 1.0]).values = array([1.0, 1.0], dtype=float)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a501d",
   "metadata": {},
   "source": [
    "# Random\n",
    "Generate a non-uniform random sample from np.arange(5) of size 3: <br>\n",
    "<code>np.random.choice(5, p=[0.1, 0, 0.3, 0.6, 0], size=3) = array([3, 3, 0]) # random</code><br>\n",
    "Flip a coin 20 times: <br>\n",
    "<code>np.random.multinomial(20, [1/2., 1/2.], size=1) = array([[8, 12]])</code><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc7bc0",
   "metadata": {},
   "source": [
    "# Hypothese Test\n",
    "- two distribution are <b>categoical</b> data, use TVD\n",
    "- two distribution are <b>numerical</b> distribution, use difference in group means or median\n",
    "\n",
    "numerical<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.choice(['H', 'T'], p=[0.55, 0.45], size=(N, 114)))\n",
    "result = df.mean(axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0104d6",
   "metadata": {},
   "source": [
    "categorical<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.random.multinomial(N, [0.1, 0.4, 0.5], size=num_rep) / N #get percentage data to calculate tvd\n",
    "np.sum(np.abs(temp - observed.to_numpy()), axis=1) / 2 #calculate tvd\n",
    "tvd = np.sum(np.abs(serie1-serie2)) / 2 # tvd only for categorical data\n",
    "(np.array(results) >= onserved).mean() # pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e760e4b",
   "metadata": {},
   "source": [
    "# Permutation Test\n",
    "normal\n",
    "```python\n",
    "to_shuffle = smoking_and_birthweight.copy()\n",
    "weights = to_shuffle['Birth Weight'].values\n",
    "\n",
    "observed_difference = (smoking_and_birthweight.groupby('Maternal Smoker')['Birth Weight'].mean().diff().iloc[-1])\n",
    "for _ in range(n_repetitions): #normal approach \n",
    "    # Step 1: Shuffle the weights\n",
    "    shuffled_weights = np.random.permutation(weights)   \n",
    "    # Step 2: Put them in a DataFrame\n",
    "    to_shuffle['Shuffled Birth Weight'] = shuffled_weights  \n",
    "    # Step 3: Compute the test statistic\n",
    "    group_means = (\n",
    "        to_shuffle\n",
    "        .groupby('Maternal Smoker')\n",
    "        .mean()\n",
    "        .loc[:, 'Shuffled Birth Weight']\n",
    "    )\n",
    "    difference = group_means.diff().iloc[-1]  \n",
    "    # Step 4: Store the result\n",
    "    faster_differences.append(difference)\n",
    "pval = (difference >= obs_diff).mean()\n",
    "```\n",
    "<b>faster</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_smoker = smoking_and_birthweight['Maternal Smoker'].values #boolean array\n",
    "weights = smoking_and_birthweight['Birth Weight'].values  #boolean array\n",
    "n_smokers = is_smoker.sum()\n",
    "n_non_smokers = 1174 - n_smokers\n",
    "\n",
    "is_smoker_permutations = np.column_stack([\n",
    "    np.random.permutation(is_smoker)\n",
    "    for _ in range(3000)\n",
    "]).T\n",
    "\n",
    "mean_smokers = (weights * is_smoker_permutations).sum(axis=1) / n_smokers\n",
    "mean_non_smokers = (weights * ~is_smoker_permutations).sum(axis=1) / n_non_smokers\n",
    "ultra_fast_differences = mean_smokers - mean_non_smokers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8800ec1",
   "metadata": {},
   "source": [
    "Use <b>Hypothesis Test</b> when given 1 sample from the population <br>\n",
    "Use <b>permutation Test</b> when given 2 observed sample from different population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e82858",
   "metadata": {},
   "source": [
    "# Missingness\n",
    "### Type of Missingness\n",
    "<b>Missing by design(MD)</b> - If you can determine whether a value is missing solely using other columns<br>\n",
    "<b>Not missing at random(NMAR or NI)</b> - The chance that a value is missing <b>depends on the actual missing value</b>!<br>\n",
    "<b>Missing at random(MAR)</b> - Missing mainly depends on other columns, <b>not</b> the missing value itself <br>\n",
    "<b>Missing completely at random(MCAR)</b> - This missingness does not depend on other column or the value itself<br>\n",
    "- use permutation tests to verify if a column is MAR vs. MCAR.\n",
    "    - Create two groups: one where values in a column are missing, and another where values in a column aren't missing.\n",
    "    - To test the missingness of column X:\n",
    "        - For every other column, test the null hypothesis \"the distribution of (other column) is the same when column X is missing and when column X is not missing.\"\n",
    "        - If you fail to reject the null, then column X's missingness does not depend on (other column).\n",
    "        - If you reject the null, then column X is MAR dependent on (other column).\n",
    "        - **If you fail to reject the null for all other columns, then column X is MCAR!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad5f19",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "<b>listwise deletion</b> - dropping entire rows that contain missing values<br>\n",
    "- porcedure: <code>.dropna()</code>\n",
    "- could delete perfectly good data in other given columns <br>\n",
    "- Drop missing data only when working with the column that contains missing data <br>\n",
    "- if data is MCAR, won't affect statistic of data<br>\n",
    "\n",
    "<b>mean imputation</b><br>\n",
    "- procedure: <code>.fillna(df[col].mean())</code> <br>\n",
    "- Preserves the mean of the observed data, for all types of missingness<br>\n",
    "- Decreases the variance of the data, for all types of missingness<br>\n",
    "- Creates a biased estimate of the true mean when the data are not MCAR<br>\n",
    "- if data is MCAR, the result mean is unbiased estimate of the true mean<br>\n",
    "\n",
    "<b>conditional mean imputation</b><br>\n",
    "- Since MAR data are MCAR within each group, perform group wise mean imputation\n",
    "- e.g.\n",
    "```python\n",
    "def mean_impute(ser):\n",
    "    return ser.fillna(ser.mean())\n",
    "heights_mar_cat.groupby('gender')['child'].transform(mean_impute)\n",
    "```\n",
    "- increase correlations between columns\n",
    "- if data MAR, result mean is unbiased estimators of the true mean, but variance is low\n",
    "- if missing values depend on more than 1 column, use linear regression to predict missing value\n",
    "\n",
    "<b>probabilistic mean imputation</b><br>\n",
    "- fill in missing data by drawing from the distribution of the <b>non-missing</b> data.\n",
    "- e.g.\n",
    "```python\n",
    "#Figure out the number of missing values\n",
    "num_null = heights_mcar['child'].isna().sum()\n",
    "#Sample that number of values from the observed dataset\n",
    "fill_values = heights_mcar.child.dropna().sample(num_null, replace=True)\n",
    "#Fill in the missing values with the sample from Step 2\n",
    "# Find the positions where values in heights_mcar are missing\n",
    "fill_values.index = heights_mcar.loc[heights_mcar['child'].isna()].index\n",
    "# Fill in the missing values\n",
    "heights_mcar_dfilled = heights_mcar.fillna({'child': fill_values.to_dict()})  # fill the vals\n",
    "```\n",
    "- need multiple imputation to reduce randomness - similar to bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b2b86",
   "metadata": {},
   "source": [
    "### The Kolmogorov-Smirnov test statistic\n",
    "The K-S test statistic measures the similarity between two distributions -- it does not quantify if one distribtution is larger then the other on average<br>\n",
    "The K-S statistic is roughly defined as the largest difference between two CDFs<br>\n",
    "<b>when to use K-S</b><br>\n",
    "If the distributions have similar shapes but are centered in different places, use the <b>difference in means</b> (or absolute difference in means) <br>\n",
    "If your alternative hypothesis involves a \"direction\" (i.e. smoking weights were are on average than non-smoking weights), use the <b>difference in means</b> <br>\n",
    "If the distributions have different shapes and your alternative hypothesis is simply that the two distributions are different, use the <b>K-S statistic</b> <br>\n",
    "e.g.<br>\n",
    "H0: the missingness of 'child' is not dependent on 'father'.<br>\n",
    "```python\n",
    "heights_mcar['child_missing'] = heights_mcar['child'].isna()\n",
    "# 'father' when 'child' is missing \n",
    "father_ch_mis = heights_mcar.loc[heights_mcar['child_missing'], 'father']\n",
    "# 'father' when 'child' is not missing\n",
    "father_ch_not_mis = heights_mcar.loc[~heights_mcar['child_missing'], 'father']\n",
    "stats.ks_2samp(father_ch_mis, father_ch_not_mis)\n",
    "```\n",
    "result is <code>KstestResult(statistic=0.055674518201284794, pvalue=0.4645992385588452)</code><br>\n",
    "fail to reject null hypothesis(MCAR); if pvalue close to 0, reject null and conclude MAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ce9dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bf7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
